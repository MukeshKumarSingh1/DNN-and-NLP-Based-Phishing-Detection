{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157747b2-15a1-4a99-b59a-53b992b551eb",
   "metadata": {},
   "source": [
    "## Phising URL Dataset collected form https://github.com/JPCERTCC/phishurl-list\n",
    "refining it for project dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d43197-874b-45b0-9ccb-8a99141a2600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data/202306.csv with 10581 URL records.\n",
      "Loaded data/202001.csv with 646 URL records.\n",
      "Loaded data/202210.csv with 5375 URL records.\n",
      "Loaded data/201901.csv with 315 URL records.\n",
      "Loaded data/202204.csv with 5397 URL records.\n",
      "Loaded data/202410.csv with 4729 URL records.\n",
      "Loaded data/201910.csv with 588 URL records.\n",
      "Loaded data/202007.csv with 950 URL records.\n",
      "Loaded data/201906.csv with 458 URL records.\n",
      "Loaded data/201909.csv with 567 URL records.\n",
      "Loaded data/202305.csv with 7250 URL records.\n",
      "Loaded data/202303.csv with 3936 URL records.\n",
      "Loaded data/201903.csv with 588 URL records.\n",
      "Loaded data/202004.csv with 971 URL records.\n",
      "Loaded data/202208.csv with 5336 URL records.\n",
      "Loaded data/201912.csv with 581 URL records.\n",
      "Loaded data/201902.csv with 434 URL records.\n",
      "Loaded data/202401.csv with 5772 URL records.\n",
      "Loaded data/202003.csv with 1124 URL records.\n",
      "Loaded data/202206.csv with 7021 URL records.\n",
      "Loaded data/202106.csv with 1626 URL records.\n",
      "Loaded data/202402.csv with 7994 URL records.\n",
      "Loaded data/202103.csv with 1102 URL records.\n",
      "Loaded data/202307.csv with 5482 URL records.\n",
      "Loaded data/202110.csv with 3614 URL records.\n",
      "Loaded data/201905.csv with 518 URL records.\n",
      "Loaded data/202201.csv with 3348 URL records.\n",
      "Loaded data/202107.csv with 1827 URL records.\n",
      "Loaded data/202006.csv with 975 URL records.\n",
      "Loaded data/202105.csv with 1586 URL records.\n",
      "Loaded data/202202.csv with 4799 URL records.\n",
      "Loaded data/202404.csv with 7267 URL records.\n",
      "Loaded data/202111.csv with 4281 URL records.\n",
      "Loaded data/202101.csv with 1134 URL records.\n",
      "Loaded data/202005.csv with 725 URL records.\n",
      "Loaded data/202308.csv with 6023 URL records.\n",
      "Loaded data/202409.csv with 2416 URL records.\n",
      "Loaded data/202207.csv with 7190 URL records.\n",
      "Loaded data/202302.csv with 2270 URL records.\n",
      "Loaded data/202212.csv with 3373 URL records.\n",
      "Loaded data/202403.csv with 6248 URL records.\n",
      "Loaded data/202203.csv with 6611 URL records.\n",
      "Loaded data/202211.csv with 2415 URL records.\n",
      "Loaded data/202406.csv with 3906 URL records.\n",
      "Loaded data/202405.csv with 5166 URL records.\n",
      "Loaded data/201907.csv with 835 URL records.\n",
      "Loaded data/202301.csv with 2040 URL records.\n",
      "Loaded data/202102.csv with 1058 URL records.\n",
      "Loaded data/202209.csv with 4902 URL records.\n",
      "Loaded data/201911.csv with 505 URL records.\n",
      "Loaded data/202408.csv with 3752 URL records.\n",
      "Loaded data/202012.csv with 1459 URL records.\n",
      "Loaded data/202310.csv with 4137 URL records.\n",
      "Loaded data/202312.csv with 6242 URL records.\n",
      "Loaded data/202309.csv with 4422 URL records.\n",
      "Loaded data/202311.csv with 4193 URL records.\n",
      "Loaded data/202009.csv with 1192 URL records.\n",
      "Loaded data/202112.csv with 3953 URL records.\n",
      "Loaded data/202109.csv with 2669 URL records.\n",
      "Loaded data/202010.csv with 1232 URL records.\n",
      "Loaded data/202407.csv with 3561 URL records.\n",
      "Loaded data/202104.csv with 1491 URL records.\n",
      "Loaded data/202205.csv with 6151 URL records.\n",
      "Loaded data/202008.csv with 1130 URL records.\n",
      "Loaded data/202304.csv with 4218 URL records.\n",
      "Loaded data/202002.csv with 830 URL records.\n",
      "Loaded data/202011.csv with 893 URL records.\n",
      "Loaded data/201908.csv with 660 URL records.\n",
      "Loaded data/201904.csv with 398 URL records.\n",
      "Loaded data/202108.csv with 3568 URL records.\n",
      "All CSV files merged into data_output/combined.csv with 220006 URL records.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_csv_files_with_urls(input_folder, output_file, url_column_name=\"url\"):\n",
    "    \"\"\"\n",
    "    Merges all CSV files in a folder into a single CSV file, keeping only the URL column.\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str): Path to the folder containing CSV files.\n",
    "        output_file (str): Path to save the merged CSV file.\n",
    "        url_column_name (str): Name of the URL column to retain.\n",
    "    \"\"\"\n",
    "    all_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"No CSV files found in the folder.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize an empty list to store DataFrames\n",
    "    data_frames = []\n",
    "    \n",
    "    for file in all_files:\n",
    "        try:\n",
    "            # Read each CSV file\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "            # Keep only the URL column\n",
    "            if url_column_name in df.columns:\n",
    "                df = df[[url_column_name]]\n",
    "                data_frames.append(df)\n",
    "                print(f\"Loaded {file} with {len(df)} URL records.\")\n",
    "            else:\n",
    "                print(f\"'{url_column_name}' column not found in {file}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {file}: {e}\")\n",
    "    \n",
    "    # Combine all DataFrames\n",
    "    if data_frames:\n",
    "        combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "        \n",
    "        # Save the combined DataFrame to a new CSV file\n",
    "        combined_df.to_csv(output_file, index=False)\n",
    "        print(f\"All CSV files merged into {output_file} with {len(combined_df)} URL records.\")\n",
    "    else:\n",
    "        print(\"No valid URL data found in the CSV files.\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = \"data/\"  # Replace with your folder containing .csv files\n",
    "output_file = \"data_output/combined.csv\"  # Replace with your desired output file name\n",
    "url_column_name = \"URL\"  # Replace with the name of the column containing URLs, if different\n",
    "\n",
    "merge_csv_files_with_urls(input_folder, output_file, url_column_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e2b63d-cca5-4667-aed7-2594dd420ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/test/Desktop/Data_gen\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733fbbba-3bdf-464a-8ef7-7f9877f902b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\n",
      "drwxrwxr-x 5 test test 4096 Feb 12 12:29 .\n",
      "drwxr-xr-x 7 test test 4096 Feb 12 12:29 ..\n",
      "drwxrwxr-x 2 test test 4096 Feb 12 12:26 data\n",
      "-rw-rw-r-- 1 test test 3103 Feb 12 12:28 data_gen.ipynb\n",
      "drwxrwxr-x 2 test test 4096 Feb 12 12:28 data_output\n",
      "drwxrwxr-x 2 test test 4096 Feb 12 12:22 .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12bed3cb-c428-4173-967a-4eb41a5cf3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 36\n",
      "drwxrwxr-x 5 test test 4096 Feb 12 12:40 .\n",
      "drwxr-xr-x 7 test test 4096 Feb 12 12:29 ..\n",
      "drwxrwxr-x 2 test test 4096 Feb 12 12:30 data\n",
      "drwxrwxr-x 2 test test 4096 Feb 12 12:31 data_output\n",
      "-rw-rw-r-- 1 test test 3900 Feb 12 12:40 email_data_gen.ipynb\n",
      "drwxrwxr-x 2 test test 4096 Feb 12 12:38 .ipynb_checkpoints\n",
      "-rw-rw-r-- 1 test test 8371 Feb 12 12:39 url_data_gen.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a00d718-6a83-4d72-ac0c-5b2a06c5c47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220006, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_output/combined.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a59c4-b991-4621-9725-b6cd329932d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
